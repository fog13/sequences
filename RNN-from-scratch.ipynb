{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-26T08:33:52.344914Z",
     "start_time": "2024-05-26T08:33:49.875242Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "In sequential models, current hidden state is a function of the current input and previous hidden state:\n",
    "\n",
    "\n",
    "### h(t) = f(h(t-1), x(t); W)\n",
    "\n",
    "W are the parameters of function (in our case NN)\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a99481283792099"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For RNN:\n",
    "\n",
    "a(t) = W * h(t-1) + U * x(t) + b1\n",
    "h(t) = tanh(a(t))\n",
    "o(t) = V * h(t) + b2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ece7e0312ae56bb5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Primary device set to GPU.\n"
     ]
    }
   ],
   "source": [
    "# Initialise device\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Primary device set to GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Primary device set to CPU.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T06:42:10.797932700Z",
     "start_time": "2024-05-03T06:42:10.726032600Z"
    }
   },
   "id": "7035227e94be1de8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#  Class for a single RNN Cell\n",
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_tensor, prev_hidden_state):\n",
    "        inner_tensor = self.hidden_layer(prev_hidden_state) + self.input_layer(input_tensor)\n",
    "        hidden_tensor = torch.tanh(inner_tensor)\n",
    "        output_tensor = self.output_layer(hidden_tensor)\n",
    "\n",
    "        return output_tensor, hidden_tensor\n",
    "\n",
    "\n",
    "# Class for RNN model composed of one or more RNN cells\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, device='cpu'):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "\n",
    "        self.rnn_cells = nn.ModuleList([RNNCell(input_size, hidden_size, output_size) for _ in range(self.num_layers)])\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, input_sequence):\n",
    "\n",
    "        batch_size = input_sequence.size(0)\n",
    "        # Different initialization techniques can be tried. For now, I am sticking to zeros\n",
    "        hidden_state = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
    "        outputs = torch.zeros(input_sequence.size(1), batch_size, self.output_size).to(self.device)\n",
    "\n",
    "        # iterate over each time step\n",
    "        for seq in range(input_sequence.shape[1]):\n",
    "            token_tensor = input_sequence[:, seq, :]\n",
    "            # iterate over each layer in rnn\n",
    "            for i, rnn_cell in enumerate(self.rnn_cells):\n",
    "                y_out, h_out = rnn_cell(token_tensor, hidden_state[i])\n",
    "                token_tensor = y_out\n",
    "\n",
    "                # update hidden state of rnn cells of layer\n",
    "                hidden_state[i] = h_out\n",
    "\n",
    "            outputs[seq] = token_tensor\n",
    "\n",
    "        return outputs.view(outputs.shape[1], outputs.shape[0], outputs.shape[2]), hidden_state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T06:42:13.112430600Z",
     "start_time": "2024-05-03T06:42:13.086879200Z"
    }
   },
   "id": "5fd855c92ec3640d",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sequence_generator(input_df, window_size, stride=1, batch_size=20000):\n",
    "    df_array = input_df.values\n",
    "    start = 0\n",
    "    total_length = len(df_array)\n",
    "    sequences = []\n",
    "    while start <= total_length - window_size:\n",
    "        sequences.append(df_array[start : start + window_size])\n",
    "        start += stride\n",
    "        \n",
    "        if len(sequences) >= batch_size:\n",
    "            yield np.array(sequences)\n",
    "            sequences = []\n",
    "    \n",
    "    if len(sequences) > 0:\n",
    "        yield np.array(sequences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T09:50:29.489401500Z",
     "start_time": "2024-05-03T09:50:29.472850600Z"
    }
   },
   "id": "575856f552873390",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def write_to_hdf5(input_df, window_size, stride_size, batch_size, storage_path):\n",
    "    sequence_data_size = int(np.floor((len(input_df) - window_size) / stride_size + 1))\n",
    "    num_features = input_df.shape[1]  # Number of features (columns) in the DataFrame\n",
    "    \n",
    "    gen = sequence_generator(input_df, window_size, stride_size, batch_size)\n",
    "    \n",
    "    with h5py.File(storage_path, 'w') as f:\n",
    "        # Create a dataset with preallocated memory for sequences and features\n",
    "        dset = f.create_dataset('sequences', (sequence_data_size, window_size, num_features), dtype='float32')\n",
    "        count = 0\n",
    "        \n",
    "        for batch in gen:\n",
    "            sequences_in_batch = batch.shape[0]\n",
    "            dset[count:count + sequences_in_batch] = batch\n",
    "            count += sequences_in_batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T09:51:14.723701600Z",
     "start_time": "2024-05-03T09:51:14.689021700Z"
    }
   },
   "id": "679712c41bee09a0",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3646, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "# class HDF5SequenceDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, file_path, sequence_length, start_idx=None, end_idx=None):\n",
    "#         self.file_path = file_path\n",
    "#         self.start_idx = start_idx\n",
    "#         self.end_idx = end_idx\n",
    "#         self.sequence_length = sequence_length\n",
    "#         self.length = end_idx - start_idx\n",
    "#     \n",
    "#         if self.length is None:\n",
    "#             with h5py.File(file_path, 'r') as file:\n",
    "#                 self.length = len(file['data/value']) - sequence_length\n",
    "# arr = [1,2,3, 4, 5, 6]\n",
    "\n",
    "df = pd.read_csv('data/daily-minimum-temperatures-in-me.csv')\n",
    "\n",
    "window_size = 5\n",
    "stride_size = 1\n",
    "batch_size = 100\n",
    "\n",
    "df['Daily minimum temperatures'] = pd.to_numeric(df['Daily minimum temperatures'], errors='coerce')\n",
    "df['Daily minimum temperatures'].fillna(method='ffill', inplace=True)\n",
    "# Fill any remaining NaNs with a default value, e.g., 0\n",
    "df['Daily minimum temperatures'].fillna(0, inplace=True)\n",
    "df['temp2'] = df['Daily minimum temperatures'] + 5\n",
    "# display(df[['Daily minimum temperatures']])\n",
    "arr = df['Daily minimum temperatures'].to_numpy()\n",
    "\n",
    "gen = sequence_generator(df[['Daily minimum temperatures', 'temp2']], window_size, stride_size, batch_size)\n",
    "arr = []\n",
    "for batch in gen:\n",
    "    batch = np.array(batch, dtype='float32')\n",
    "    arr.append(batch)\n",
    "    \n",
    "sequence = np.concatenate(arr, axis=0)\n",
    "\n",
    "\n",
    "print(sequence.shape)\n",
    "# write_to_hdf5(arr, window_size, stride_size, batch_size, 'meta/sequence.h5')\n",
    "\n",
    "input_size = len(arr) \n",
    "\n",
    "# with h5py.File('meta/sequence.h5', 'r') as f:\n",
    "#     data = f['sequences'][:]\n",
    "#     print(data.shape)\n",
    "#     \n",
    "#     # Sample 5 random sequences\n",
    "#     indices = np.random.randint(0, data.shape[0], 500)\n",
    "#     for idx in indices:\n",
    "#         print(f\"Sample data at index {idx}: {data[idx]}\")\n",
    "#         print(data[idx] == sequence[idx])\n",
    "# sequence_data_size = np.floor( (input_size - window_size) / stride_size + 1 )\n",
    "# \n",
    "# input_size = len(arr)\n",
    "# gen = sequence_generator(arr, 5, 3, 2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T09:53:16.521305200Z",
     "start_time": "2024-05-03T09:53:16.458192500Z"
    }
   },
   "id": "5171a0e06044690e",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "num_layers = 2\n",
    "\n",
    "model = RNN(input_size, hidden_size, output_size, num_layers, device.__str__()).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T05:11:55.632020900Z",
     "start_time": "2024-04-27T05:11:55.528411300Z"
    }
   },
   "id": "4ad77b1e83f8d111",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                          object\n",
      "Daily minimum temperatures    object\n",
      "dtype: object\n",
      "(3650, 2)\n",
      "3650\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/daily-minimum-temperatures-in-me.csv')\n",
    "print(df.dtypes)\n",
    "print(df.shape)\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T05:11:56.671277500Z",
     "start_time": "2024-04-27T05:11:56.654250800Z"
    }
   },
   "id": "8737a4d7d00ee502",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "            Date Daily minimum temperatures\n0       1/1/1981                       20.7\n1       1/2/1981                       17.9\n2       1/3/1981                       18.8\n3       1/4/1981                       14.6\n4       1/5/1981                       15.8\n...          ...                        ...\n3645  12/27/1990                         14\n3646  12/28/1990                       13.6\n3647  12/29/1990                       13.5\n3648  12/30/1990                       15.7\n3649  12/31/1990                         13\n\n[3650 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Daily minimum temperatures</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1/1/1981</td>\n      <td>20.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1/2/1981</td>\n      <td>17.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1/3/1981</td>\n      <td>18.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1/4/1981</td>\n      <td>14.6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1/5/1981</td>\n      <td>15.8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3645</th>\n      <td>12/27/1990</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3646</th>\n      <td>12/28/1990</td>\n      <td>13.6</td>\n    </tr>\n    <tr>\n      <th>3647</th>\n      <td>12/29/1990</td>\n      <td>13.5</td>\n    </tr>\n    <tr>\n      <th>3648</th>\n      <td>12/30/1990</td>\n      <td>15.7</td>\n    </tr>\n    <tr>\n      <th>3649</th>\n      <td>12/31/1990</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n<p>3650 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                          object\n",
      "Daily minimum temperatures    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/daily-minimum-temperatures-in-me.csv')\n",
    "df.to_hdf('meta/temperature.h5', mode='w', key='temperature' , format='table')\n",
    "display(df)\n",
    "print(df.dtypes)\n",
    "df['Daily minimum temperatures'] = pd.to_numeric(df['Daily minimum temperatures'], errors='coerce').astype('float32')\n",
    "arr = df['Daily minimum temperatures'].tolist()\n",
    "\n",
    "window_size = 14\n",
    "sequenceArr = [arr[i:i + window_size + 1] for i in range(len(arr) - window_size)]\n",
    "\n",
    "assert len(sequenceArr) + window_size == len(arr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T05:11:40.098655800Z",
     "start_time": "2024-04-27T05:11:40.050019900Z"
    }
   },
   "id": "68d8bd41bbf39d6a",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Not the most optimal and accurate way to perform train test split\n",
    "def generate_train_test_split(arr, train_ratio = 0.8):\n",
    "    # Dont shuffle since this is a time series\n",
    "    # random.shuffle(arr)\n",
    "    \n",
    "    train_size = round(len(arr) * train_ratio)\n",
    "    train_arr = arr[:train_size]\n",
    "    test_arr = arr[train_size:]\n",
    "    \n",
    "    return train_arr, test_arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T12:46:06.044048700Z",
     "start_time": "2024-04-26T12:46:06.036537400Z"
    }
   },
   "id": "bbfb826dfa363fc5",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### First train raw data without any preprocessing whatsoever"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a729f5f3bc9c279d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(3272, 364, 3636)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arr, test_arr = generate_train_test_split(sequenceArr, 0.9)\n",
    "\n",
    "len(train_arr), len(test_arr), len(sequenceArr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T12:46:08.513611700Z",
     "start_time": "2024-04-26T12:46:08.486438700Z"
    }
   },
   "id": "151530f6bc7ba069",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "\n",
    "model = RNN(input_size, hidden_size, output_size, num_layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T12:46:13.294416900Z",
     "start_time": "2024-04-26T12:46:13.272033400Z"
    }
   },
   "id": "549915ca0742d999",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "moduleList = nn.ModuleList([RNNCell(input_size, hidden_size, output_size) for _ in range(5)])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T12:46:13.584904300Z",
     "start_time": "2024-04-26T12:46:13.577391800Z"
    }
   },
   "id": "895501aea8d7dac9",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.6038],\n",
      "         [-0.6036],\n",
      "         [-0.6037],\n",
      "         [-0.6026],\n",
      "         [-0.6032],\n",
      "         [-0.6032],\n",
      "         [-0.6032],\n",
      "         [-0.6035],\n",
      "         [-0.6037],\n",
      "         [-0.6037],\n",
      "         [-0.6033],\n",
      "         [-0.6014],\n",
      "         [-0.6034],\n",
      "         [-0.6037],\n",
      "         [-0.6038]]], grad_fn=<ViewBackward0>), tensor([[[ 1.0000,  1.0000, -1.0000, -1.0000]]], grad_fn=<CopySlices>))\n"
     ]
    }
   ],
   "source": [
    "input_sample = torch.Tensor(train_arr[0])\n",
    "input_sample = input_sample.view(1, input_sample.shape[0], 1)\n",
    "print(model(input_sample))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T12:46:13.945286300Z",
     "start_time": "2024-04-26T12:46:13.901179Z"
    }
   },
   "id": "6bf77ab2155607f3",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(14, 10, 15)\n",
    "x.size(-2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T06:55:02.322455Z",
     "start_time": "2024-03-16T06:55:02.293204300Z"
    }
   },
   "id": "eb9125cd5cac234b",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m num \u001B[38;5;129;01min\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mTensor(\u001B[43msequence\u001B[49m[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(num)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'sequence' is not defined"
     ]
    }
   ],
   "source": [
    "for num in torch.Tensor(sequence[0]):\n",
    "    print(num)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T06:55:04.013143700Z",
     "start_time": "2024-03-16T06:55:03.718406900Z"
    }
   },
   "id": "943836c350ab64fd",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 2, 2, 3])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros([2,2,2])\n",
    "b = torch.ones([2,2,2])\n",
    "c = torch.full([2,2,2], 5)\n",
    "torch.stack((a,b,c), dim=3).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T15:05:46.884271Z",
     "start_time": "2024-04-13T15:05:46.857266100Z"
    }
   },
   "id": "d0edbcf99cb768e5",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 3],\n        [1, 3]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.full([2], 1)\n",
    "b = torch.full([2], 3)\n",
    "torch.stack((a,b), dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T15:03:10.489704800Z",
     "start_time": "2024-04-13T15:03:10.473703400Z"
    }
   },
   "id": "693fe67127e4de27",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(2.5/1.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T07:36:53.533067900Z",
     "start_time": "2024-05-03T07:36:53.511424600Z"
    }
   },
   "id": "c6b059599a3e4daf",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "887aadcb49c9be6c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
