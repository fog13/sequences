{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-03T14:00:27.631298Z",
     "start_time": "2024-06-03T14:00:20.178475Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "In sequential models, current hidden state is a function of the current input and previous hidden state:\n",
    "\n",
    "\n",
    "### h(t) = f(h(t-1), x(t); W)\n",
    "\n",
    "W are the parameters of function (in our case NN)\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a99481283792099"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For RNN:\n",
    "\n",
    "a(t) = W * h(t-1) + U * x(t) + b1\n",
    "h(t) = tanh(a(t))\n",
    "o(t) = V * h(t) + b2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ece7e0312ae56bb5"
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialise device\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Primary device set to GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Primary device set to CPU.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T14:00:46.173135Z",
     "start_time": "2024-06-03T14:00:46.084199Z"
    }
   },
   "id": "7035227e94be1de8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Primary device set to GPU.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "#  Class for a single RNN Cell\n",
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_tensor, prev_hidden_state):\n",
    "        inner_tensor = self.hidden_layer(prev_hidden_state) + self.input_layer(input_tensor)\n",
    "        hidden_tensor = torch.tanh(inner_tensor)\n",
    "        output_tensor = self.output_layer(hidden_tensor)\n",
    "\n",
    "        return output_tensor, hidden_tensor\n",
    "\n",
    "\n",
    "# Class for RNN model composed of one or more RNN cells\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, device='cpu'):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "\n",
    "        self.rnn_cells = nn.ModuleList([RNNCell(input_size, hidden_size, output_size) for _ in range(self.num_layers)])\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, input_sequence):\n",
    "\n",
    "        batch_size = input_sequence.size(0)\n",
    "        sequence_size = input_sequence.size(1)\n",
    "        # Different initialization techniques can be tried. For now, I am sticking to zeros\n",
    "        hidden_state = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
    "        outputs = torch.zeros(sequence_size, batch_size, self.output_size).to(self.device)\n",
    "\n",
    "        # iterate over each time step\n",
    "        for seq in range(sequence_size):\n",
    "            token_tensor = input_sequence[:, seq, :]\n",
    "            # iterate over each layer in rnn\n",
    "            for i, rnn_cell in enumerate(self.rnn_cells):\n",
    "                y_out, h_out = rnn_cell(token_tensor, hidden_state[i])\n",
    "                token_tensor = y_out\n",
    "\n",
    "                # update hidden state of rnn cells of layer\n",
    "                hidden_state[i] = h_out\n",
    "\n",
    "            outputs[seq] = token_tensor\n",
    "\n",
    "        return outputs.view(outputs.shape[1], outputs.shape[0], outputs.shape[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T14:00:47.798385Z",
     "start_time": "2024-06-03T14:00:47.779100Z"
    }
   },
   "id": "5fd855c92ec3640d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "def sequence_generator(input_df, window_size, stride=1, batch_size=20000):\n",
    "    df_array = input_df.values\n",
    "    start = 0\n",
    "    total_length = len(df_array)\n",
    "    sequences = []\n",
    "    outputs = []\n",
    "    while start < total_length - window_size:\n",
    "        sequences.append(df_array[start : start + window_size])\n",
    "        outputs.append(df_array[start+window_size])\n",
    "        start += stride\n",
    "        \n",
    "        if len(sequences) >= batch_size:\n",
    "            yield np.array(sequences), np.array(outputs)\n",
    "            sequences = []\n",
    "            outputs = []\n",
    "    \n",
    "    if len(sequences) > 0:\n",
    "        yield np.array(sequences), np.array(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T14:14:39.250997Z",
     "start_time": "2024-06-03T14:14:39.236489Z"
    }
   },
   "id": "575856f552873390",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def write_to_hdf5(input_df, window_size, stride_size, batch_size, storage_path, dataset_name, \n",
    "                  label_name = 'label'):\n",
    "    sequence_data_size = int(np.floor((len(input_df) - window_size) / stride_size + 1))\n",
    "    num_features = input_df.shape[1]  # Number of features (columns) in the DataFrame\n",
    "    \n",
    "    gen = sequence_generator(input_df, window_size, stride_size, batch_size)\n",
    "    \n",
    "    with h5py.File(storage_path, 'w') as f:\n",
    "        # Create a dataset with preallocated memory for sequences and features\n",
    "        dset = f.create_dataset(dataset_name, (sequence_data_size, window_size, num_features), dtype='float32')\n",
    "        y_set = f.create_dataset(label_name, sequence_data_size)\n",
    "        count = 0\n",
    "        \n",
    "        for batch in gen:\n",
    "            features = batch[0]\n",
    "            y = batch[1]\n",
    "            num_data = features.shape[0]\n",
    "            dset[count:count + num_data] = features\n",
    "            y_set[count: count + num_data] = np.squeeze(y)\n",
    "            count += num_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T14:22:22.980201Z",
     "start_time": "2024-06-03T14:22:22.966689Z"
    }
   },
   "id": "679712c41bee09a0",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "# class HDF5SequenceDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, file_path, sequence_length, start_idx=None, end_idx=None):\n",
    "#         self.file_path = file_path\n",
    "#         self.start_idx = start_idx\n",
    "#         self.end_idx = end_idx\n",
    "#         self.sequence_length = sequence_length\n",
    "#         self.length = end_idx - start_idx\n",
    "#     \n",
    "#         if self.length is None:\n",
    "#             with h5py.File(file_path, 'r') as file:\n",
    "#                 self.length = len(file['data/value']) - sequence_length\n",
    "# arr = [1,2,3, 4, 5, 6]\n",
    "\n",
    "df = pd.read_csv('data/daily-minimum-temperatures-in-me.csv')\n",
    "\n",
    "window_size = 5\n",
    "stride_size = 1\n",
    "batch_size = 100\n",
    "\n",
    "df['Daily minimum temperatures'] = pd.to_numeric(df['Daily minimum temperatures'], errors='coerce')\n",
    "df['Daily minimum temperatures'].fillna(method='ffill', inplace=True)\n",
    "# Fill any remaining NaNs with a default value, e.g., 0\n",
    "df['Daily minimum temperatures'].fillna(0, inplace=True)\n",
    "df['temp2'] = df['Daily minimum temperatures'] + 5\n",
    "# display(df[['Daily minimum temperatures']])\n",
    "arr = df['Daily minimum temperatures'].to_numpy()\n",
    "\n",
    "gen = sequence_generator(df[['Daily minimum temperatures']], window_size, stride_size, batch_size)\n",
    "arr_x = []\n",
    "arr_y = []\n",
    "for batch in gen:\n",
    "    x = batch[0]\n",
    "    y = batch[1]\n",
    "    arr_x.append(x)\n",
    "    arr_y.append(y)\n",
    "    \n",
    "sequence_x = np.concatenate(arr_x, axis=0)\n",
    "sequence_y = np.concatenate(arr_y, axis=0)\n",
    "\n",
    "\n",
    "print(sequence_x.shape)\n",
    "print(sequence_y.shape)\n",
    "\n",
    "# print(sequence_x)\n",
    "# print(sequence_y)\n",
    "# write_to_hdf5(arr, window_size, stride_size, batch_size, 'meta/sequence.h5')\n",
    "\n",
    "write_to_hdf5(df[['Daily minimum temperatures']], window_size, stride_size, batch_size, 'meta/sequence.h5', 'sequences')\n",
    "input_size = len(arr) \n",
    "\n",
    "# with h5py.File('meta/sequence.h5', 'r') as f:\n",
    "#     data = f['sequences'][:]\n",
    "#     print(data.shape)\n",
    "#     \n",
    "#     # Sample 5 random sequences\n",
    "#     indices = np.random.randint(0, data.shape[0], 500)\n",
    "#     for idx in indices:\n",
    "#         print(f\"Sample data at index {idx}: {data[idx]}\")\n",
    "#         print(data[idx] == sequence[idx])\n",
    "# sequence_data_size = np.floor( (input_size - window_size) / stride_size + 1 )\n",
    "# \n",
    "# input_size = len(arr)\n",
    "# gen = sequence_generator(arr, 5, 3, 2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T14:22:23.452652Z",
     "start_time": "2024-06-03T14:22:23.412590Z"
    }
   },
   "id": "5171a0e06044690e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(100, 5, 1) (100, 1)\n",
      "(45, 5, 1) (45, 1)\n",
      "(3645, 5, 1)\n",
      "(3645, 1)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:25:38.623077Z",
     "start_time": "2024-06-03T14:25:38.608562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HDF5Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, file_path, dataset_name, label_name = 'label', transform = None):\n",
    "        self.file_path = file_path\n",
    "        self.dataset_name = dataset_name\n",
    "        self.label_name = label_name\n",
    "        self.transform = transform\n",
    "        self.file = None\n",
    "        self.data_len = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.data_len is None:\n",
    "            with h5py.File(self.file_path, 'r') as file:\n",
    "                self.data_len = len(file[self.dataset_name])\n",
    "            return self.data_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.file is None:\n",
    "            self.file = h5py.File(self.file_path, 'r')\n",
    "        x_in = self.file[self.dataset_name][index]\n",
    "        label = self.file[self.label_name][index]\n",
    "        if self.transform is not None:\n",
    "            x_in = self.transform(x_in)\n",
    "        return x_in, label\n",
    "    \n",
    "    def close(self):\n",
    "        if self.file is not None:\n",
    "            self.file.close()\n",
    "            self.file = None\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.close()"
   ],
   "id": "9fa2f03681682935",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:27:16.992964Z",
     "start_time": "2024-06-03T14:27:16.978444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hdf_dataset = HDF5Dataset('meta/sequence.h5', 'sequences', 'label')\n",
    "hdf_dataset.__getitem__(2)"
   ],
   "id": "a198d999aaa81415",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[18.8],\n",
       "        [14.6],\n",
       "        [15.8],\n",
       "        [15.8],\n",
       "        [15.8]], dtype=float32),\n",
       " 17.4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "input_size = 1\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "num_layers = 2\n",
    "\n",
    "model = RNN(input_size, hidden_size, output_size, num_layers, device).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T16:20:24.766938Z",
     "start_time": "2024-06-02T16:20:24.747427Z"
    }
   },
   "id": "4ad77b1e83f8d111",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/daily-minimum-temperatures-in-me.csv')\n",
    "print(df.dtypes)\n",
    "print(df.shape)\n",
    "print(len(df))\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T14:27:05.827781Z",
     "start_time": "2024-06-03T14:27:05.806753Z"
    }
   },
   "id": "8737a4d7d00ee502",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                          object\n",
      "Daily minimum temperatures    object\n",
      "dtype: object\n",
      "(3650, 2)\n",
      "3650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        Date Daily minimum temperatures\n",
       "0   1/1/1981                       20.7\n",
       "1   1/2/1981                       17.9\n",
       "2   1/3/1981                       18.8\n",
       "3   1/4/1981                       14.6\n",
       "4   1/5/1981                       15.8\n",
       "5   1/6/1981                       15.8\n",
       "6   1/7/1981                       15.8\n",
       "7   1/8/1981                       17.4\n",
       "8   1/9/1981                       21.8\n",
       "9  1/10/1981                         20"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Daily minimum temperatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/1981</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/1981</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/1981</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/4/1981</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/5/1981</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/6/1981</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/7/1981</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/8/1981</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/9/1981</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/10/1981</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/daily-minimum-temperatures-in-me.csv')\n",
    "df.to_hdf('meta/temperature.h5', mode='w', key='temperature' , format='table')\n",
    "display(df)\n",
    "print(df.dtypes)\n",
    "df['Daily minimum temperatures'] = pd.to_numeric(df['Daily minimum temperatures'], errors='coerce').astype('float32')\n",
    "arr = df['Daily minimum temperatures'].tolist()\n",
    "\n",
    "window_size = 14\n",
    "sequenceArr = [arr[i:i + window_size + 1] for i in range(len(arr) - window_size)]\n",
    "\n",
    "assert len(sequenceArr) + window_size == len(arr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T16:20:27.000234Z",
     "start_time": "2024-06-02T16:20:26.964471Z"
    }
   },
   "id": "68d8bd41bbf39d6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Date Daily minimum temperatures\n",
       "0       1/1/1981                       20.7\n",
       "1       1/2/1981                       17.9\n",
       "2       1/3/1981                       18.8\n",
       "3       1/4/1981                       14.6\n",
       "4       1/5/1981                       15.8\n",
       "...          ...                        ...\n",
       "3645  12/27/1990                         14\n",
       "3646  12/28/1990                       13.6\n",
       "3647  12/29/1990                       13.5\n",
       "3648  12/30/1990                       15.7\n",
       "3649  12/31/1990                         13\n",
       "\n",
       "[3650 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Daily minimum temperatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/1981</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/1981</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/1981</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/4/1981</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/5/1981</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>12/27/1990</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>12/28/1990</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>12/29/1990</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>12/30/1990</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>12/31/1990</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3650 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                          object\n",
      "Daily minimum temperatures    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Not the most optimal way to perform train test split on time series\n",
    "def generate_train_test_split(arr, train_ratio = 0.8):\n",
    "    # Don't shuffle since this is a time series\n",
    "    # random.shuffle(arr)\n",
    "    \n",
    "    train_size = round(len(arr) * train_ratio)\n",
    "    train_arr = arr[:train_size]\n",
    "    test_arr = arr[train_size:]\n",
    "    \n",
    "    return train_arr, test_arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T16:20:28.066465Z",
     "start_time": "2024-06-02T16:20:28.051464Z"
    }
   },
   "id": "bbfb826dfa363fc5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "### First train raw data without any preprocessing whatsoever"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a729f5f3bc9c279d"
  },
  {
   "cell_type": "code",
   "source": [
    "train_arr, test_arr = generate_train_test_split(sequenceArr, 0.9)\n",
    "\n",
    "len(train_arr), len(test_arr), len(sequenceArr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T16:20:31.126434Z",
     "start_time": "2024-06-02T16:20:31.117435Z"
    }
   },
   "id": "151530f6bc7ba069",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3272, 364, 3636)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "input_size = 1\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "\n",
    "model = RNN(input_size, hidden_size, output_size, num_layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T16:20:34.227944Z",
     "start_time": "2024-06-02T16:20:34.218947Z"
    }
   },
   "id": "549915ca0742d999",
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "moduleList = nn.ModuleList([RNNCell(input_size, hidden_size, output_size) for _ in range(5)])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T15:33:16.419557Z",
     "start_time": "2024-06-02T15:33:16.408558Z"
    }
   },
   "id": "895501aea8d7dac9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "input_sample = torch.Tensor(train_arr[0:3])\n",
    "input_sample = input_sample.view(1, input_sample.shape[0], 1)\n",
    "model_out = model(input_sample)\n",
    "model_out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T16:21:20.611806Z",
     "start_time": "2024-06-02T16:21:20.588807Z"
    }
   },
   "id": "6bf77ab2155607f3",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 3, 1]' is invalid for input of size 45",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m input_sample \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor(train_arr[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m3\u001B[39m])\n\u001B[1;32m----> 2\u001B[0m input_sample \u001B[38;5;241m=\u001B[39m \u001B[43minput_sample\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_sample\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m model_out \u001B[38;5;241m=\u001B[39m model(input_sample)\n\u001B[0;32m      4\u001B[0m model_out\n",
      "\u001B[1;31mRuntimeError\u001B[0m: shape '[1, 3, 1]' is invalid for input of size 45"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "for batch in gen:\n",
    "    print(batch.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T16:23:11.707342Z",
     "start_time": "2024-06-02T16:23:11.703343Z"
    }
   },
   "id": "eb9125cd5cac234b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": [
    "for num in torch.Tensor(sequence[0]):\n",
    "    print(num)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T15:33:47.109771Z",
     "start_time": "2024-06-02T15:33:47.101773Z"
    }
   },
   "id": "943836c350ab64fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20.7000, 25.7000])\n",
      "tensor([17.9000, 22.9000])\n",
      "tensor([18.8000, 23.8000])\n",
      "tensor([14.6000, 19.6000])\n",
      "tensor([15.8000, 20.8000])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "filePath = 'meta/sequence.h5'\n",
    "\n",
    "with h5py.File(filePath, 'r') as file:\n",
    "    data = file['sequences']\n",
    "    dataArray = data[:3]\n",
    "\n",
    "    print(model(torch.Tensor(dataArray)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:15:32.627595Z",
     "start_time": "2024-06-03T08:15:32.613009Z"
    }
   },
   "id": "d0edbcf99cb768e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9110],\n",
      "         [0.9160],\n",
      "         [0.9141],\n",
      "         [0.9934],\n",
      "         [0.9789]],\n",
      "\n",
      "        [[1.0464],\n",
      "         [0.9601],\n",
      "         [1.0233],\n",
      "         [0.9816],\n",
      "         [1.0301]],\n",
      "\n",
      "        [[0.9887],\n",
      "         [1.0026],\n",
      "         [0.9866],\n",
      "         [1.0002],\n",
      "         [0.9957]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 3],\n        [1, 3]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.full([2], 1)\n",
    "b = torch.full([2], 3)\n",
    "torch.stack((a,b), dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T15:03:10.489704800Z",
     "start_time": "2024-04-13T15:03:10.473703400Z"
    }
   },
   "id": "693fe67127e4de27",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(2.5/1.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T07:36:53.533067900Z",
     "start_time": "2024-05-03T07:36:53.511424600Z"
    }
   },
   "id": "c6b059599a3e4daf",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "887aadcb49c9be6c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
